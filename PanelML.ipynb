{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KÜTÜPHANE EKLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.api import SARIMAX, api as smt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import OneClassSVM, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KORELASYON VE ÖZELLİK HESAPLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'organised_data_final.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "correlation_with_OUP = data.corr()['OUP'].drop('OUP')  # 'OUP' hariç diğer değişkenlerle korelasyon\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = correlation_with_OUP.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Değişkenler')\n",
    "plt.ylabel('Korelasyon')\n",
    "plt.title('OUP Değişkeninin Diğer Değişkenlerle Korelasyonu')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.01, f'{bar.get_height():.2f}', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "\n",
    "# Veri setinin temel istatistiksel özetini almak\n",
    "summary_stats = data.describe()\n",
    "summary_stats.to_excel('summary_stats.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AYKIRI DEĞERLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dosya_yolu = 'organised_data_final.xlsx'\n",
    "veri = pd.read_excel(dosya_yolu)\n",
    "\n",
    "veri = veri.dropna()\n",
    "\n",
    "# Modified Z-Score hesaplama\n",
    "mad = median_abs_deviation(veri)\n",
    "modified_z_scores = 0.6745 * (veri - veri.median()) / mad\n",
    "\n",
    "# Aykırı değerleri saptama ve işaretleme\n",
    "threshold = 3.5  # Eşik değeri\n",
    "aykiri_degerler = (abs(modified_z_scores) > threshold).any(axis=1)\n",
    "\n",
    "# Isolation Forest kullanarak aykırı değerleri saptama\n",
    "model = IsolationForest(contamination=0.1)  # Kontaminasyon oranı\n",
    "model.fit(veri)\n",
    "isolation_outliers = model.predict(veri)\n",
    "\n",
    "# Aykırı değerleri görselleştirme\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(veri.index, veri['OUP'], c=aykiri_degerler, cmap='coolwarm')\n",
    "plt.title('Modified Z-Score ile Aykırı Değerler')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(veri.index, veri['OUP'], c=isolation_outliers, cmap='coolwarm')\n",
    "plt.title('Isolation Forest ile Aykırı Değerler')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÖNEMLİLİK SKORLARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('organised_data_final.xlsx')\n",
    "\n",
    "df_clean = df.dropna()\n",
    "\n",
    "X = df_clean[['WDS', 'MXT', 'TMP', 'MNT', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR']]\n",
    "y = df_clean['OUP']\n",
    "\n",
    "X.columns = ['WDS', 'MXT', 'TMP', 'MNT', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR']\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Özellik önemlilik hesaplama\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Özellik önemlilik skorlarını saklamak için bir DataFrame oluşturun\n",
    "feature_importance_df = pd.DataFrame({'Özellik': X.columns, 'Önemlilik': feature_importance})\n",
    "\n",
    "# Özellikleri önemlilik skorlarına göre azalan sırada sıralayın\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Önemlilik', ascending=False)\n",
    "\n",
    "# Özellik önemliliklerini görselleştirme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Özellik'], feature_importance_df['Önemlilik'], color='skyblue')\n",
    "plt.xlabel('Özellik Önemlilik Skoru')\n",
    "plt.title('Özellik Önemlilik Skorları')  # En önemli özelliğin üstte olması için y-eksenini ters çevirme\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOĞRULAMA SKORU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'organised_data_final.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "columns_with_missing_values = ['WDS','MXT', 'MNT', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "\n",
    "rows_with_missing_values = data[columns_with_missing_values].isnull().any(axis=1)\n",
    "\n",
    "data_with_missing_values = data[rows_with_missing_values]\n",
    "\n",
    "data_without_missing_values = data.drop(columns_with_missing_values, axis=1)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed_data = imputer.fit_transform(data_without_missing_values)\n",
    "\n",
    "model = XGBRegressor()\n",
    "\n",
    "scores = cross_val_score(model, imputed_data[~rows_with_missing_values], data[columns_with_missing_values][~rows_with_missing_values], scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "print(\"Çapraz doğrulama skorları: \", scores)\n",
    "print(\"Ortalama çapraz doğrulama skoru: \", scores.mean())\n",
    "\n",
    "# Skorları grafiğe dökme\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, len(scores)+1), -scores, color='skyblue')\n",
    "plt.xlabel('Çapraz Doğrulama Parçası')\n",
    "plt.ylabel('Negatif MSE Skoru')\n",
    "plt.title('XGBoost Regressor Çapraz Doğrulama Skorları')\n",
    "plt.ylim(min(-scores)*0.9, max(-scores)*1.1)  # Grafik aralığını düzenleme\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KARŞILIKLI BİLGİ DEĞERLERİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'organised_data_final.xlsx'\n",
    "ata = pd.read_excel(file_path)\n",
    "data = data.dropna()\n",
    "\n",
    "# Özellikler ve hedef değişkeni seçme\n",
    "features = data.drop(['YEAR', 'MONTH', 'DAY', 'HOUR', 'OUP'], axis=1)  # Örnek olarak tarih sütunları çıkarıldı\n",
    "target = data['OUP']\n",
    "\n",
    "# Karşılıklı bilgi (mutual information) hesaplama\n",
    "mutual_info = mutual_info_regression(features, target)\n",
    "\n",
    "# Her özelliğin karşılıklı bilgi değerlerini içeren bir DataFrame oluşturma\n",
    "mi_df = pd.DataFrame({'Feature': features.columns, 'Mutual_Info': mutual_info})\n",
    "\n",
    "# Çubuk grafiği oluşturma\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Mutual_Info', y='Feature', data=mi_df.sort_values(by='Mutual_Info', ascending=False))\n",
    "plt.title('Karşılıklı Bilgi Değerleri')\n",
    "plt.xlabel('Karşılıklı Bilgi')\n",
    "plt.ylabel('Özellikler')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'organised_data_final.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "columns_to_drop = ['MXT', 'MNT']\n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "columns_with_missing_values = ['WDS', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "\n",
    "for column in columns_with_missing_values:\n",
    "    missing_values_indices = data[data[column].isnull()].index\n",
    "    \n",
    "    train_data = data[~data[column].isnull()]\n",
    "    model = SARIMAX(train_data[column], order=(2, 1, 2), seasonal_order=(2, 0, 1, 24))  # SARIMAX modeli örneği\n",
    "    \n",
    "    fitted_model = model.fit()\n",
    "    \n",
    "    predicted_values = fitted_model.predict(start=missing_values_indices[0], end=missing_values_indices[-1])\n",
    "    \n",
    "    data.loc[missing_values_indices, column] = predicted_values\n",
    "\n",
    "output_file = 'data1.xlsx'\n",
    "data.to_excel(output_file, index=False)\n",
    "\n",
    "file_path = 'data1.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "data2['RLH'] = data2['RLH'].astype(int)\n",
    "\n",
    "data2['DATE'] = pd.to_datetime(data2[['YEAR', 'MONTH', 'DAY']])\n",
    "data2['DATE'] = data2['DATE'].dt.date\n",
    "\n",
    "ordered_columns = ['DATE', 'HOUR', 'WDS', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "data2 = data2[ordered_columns]\n",
    "\n",
    "output_file_updated = 'data1.xlsx'\n",
    "data2.to_excel(output_file_updated, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBREGRESSOR EN İYİ PARAMETRE VE SKOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Özellikler ve hedef değişkeni seç\n",
    "features = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'WDS', 'MXT', 'MNT', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR']\n",
    "target = 'OUP'\n",
    "\n",
    "# Eksik değerleri içermeyen veriyi seç ve eğitim/test setlerine ayır\n",
    "data_without_missing = data.dropna(subset=features + [target])\n",
    "train, test = train_test_split(data_without_missing, test_size=0.3, random_state=42)\n",
    "\n",
    "# Eğitim setini ve test setini eksik verileri doldurmadan kullan\n",
    "train_features = train[features]\n",
    "train_target = train[target]\n",
    "\n",
    "# XGBoost modelini tanımla\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Grid Search için parametre grid'i oluştur\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Grid Search ile en iyi parametreleri bul\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(train_features, train_target)\n",
    "\n",
    "# En iyi parametreleri ve skorları göster\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "print(\"En iyi skor:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBREGRESSOR MODEL EĞİTİMİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Eksik değerlerin olduğu sütunlar\n",
    "columns_with_missing_values = ['WDS', 'MXT', 'MNT', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "\n",
    "# Eksik değerlerin bulunduğu satırların indeksleri\n",
    "rows_with_missing_values = data[columns_with_missing_values].isnull().any(axis=1)\n",
    "data_with_missing_values = data[rows_with_missing_values]\n",
    "data_without_missing_values = data.drop(columns_with_missing_values, axis=1)\n",
    "\n",
    "# XGBRegressor için en iyi parametreler\n",
    "best_params = {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
    "\n",
    "# Imputer tanımla\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "for column in columns_with_missing_values:\n",
    "    features = data_without_missing_values\n",
    "    target = data[column]\n",
    "\n",
    "    # Model oluştur\n",
    "    model = XGBRegressor(**best_params)\n",
    "\n",
    "    # Eksik değerleri tahmin et\n",
    "    imputed_features = imputer.fit_transform(features)\n",
    "    model.fit(imputed_features[~rows_with_missing_values], target[~rows_with_missing_values])\n",
    "\n",
    "    missing_values_indices = data_with_missing_values[data_with_missing_values[column].isnull()].index\n",
    "    missing_values_features = data_without_missing_values.iloc[missing_values_indices]\n",
    "    predicted_values = model.predict(imputer.transform(missing_values_features))\n",
    "\n",
    "    # Eksik değerleri doldur\n",
    "    data.loc[missing_values_indices, column] = predicted_values\n",
    "\n",
    "# Yeni veri setini kaydet\n",
    "output_file = 'data2.xlsx'\n",
    "data.to_excel(output_file, index=False)\n",
    "\n",
    "file_path = 'data2.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "data2['RLH'] = data2['RLH'].astype(int)\n",
    "\n",
    "data2['DATE'] = pd.to_datetime(data2[['YEAR', 'MONTH', 'DAY']])\n",
    "data2['DATE'] = data2['DATE'].dt.date\n",
    "\n",
    "ordered_columns = ['DATE', 'HOUR', 'WDS', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "data2 = data2[ordered_columns]\n",
    "\n",
    "output_file_updated = 'data2.xlsx'\n",
    "data2.to_excel(output_file_updated, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE MODEL EĞİTİMİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'organised_data_final.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "columns_with_missing_values = ['WDS', 'MXT', 'MNT', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "\n",
    "data_without_missing_values = data.drop(columns_with_missing_values, axis=1)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# En iyi parametreleri bulmak için GridSearchCV kullanarak DecisionTreeRegressor'ı ayarlayın\n",
    "param_grid = {\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "for column in columns_with_missing_values:\n",
    "    features = data_without_missing_values\n",
    "    target = data[column]\n",
    "\n",
    "    # Eksik değerlerin olduğu satırları belirleyin\n",
    "    rows_with_missing_values = target.isnull()\n",
    "\n",
    "    # Eğitim için en iyi parametreleri bulun\n",
    "    grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "    grid_search.fit(features[~rows_with_missing_values], target[~rows_with_missing_values])\n",
    "    best_params[column] = grid_search.best_params_\n",
    "\n",
    "# En iyi parametrelerle modelleri eğitin ve eksik değerleri doldurun\n",
    "for column in columns_with_missing_values:\n",
    "    features = data_without_missing_values\n",
    "    target = data[column]\n",
    "\n",
    "    rows_with_missing_values = target.isnull()\n",
    "\n",
    "    model = DecisionTreeRegressor(**best_params[column])\n",
    "    imputed_features = imputer.fit_transform(features)\n",
    "    model.fit(imputed_features[~rows_with_missing_values], target[~rows_with_missing_values])\n",
    "\n",
    "    missing_values_indices = target[rows_with_missing_values].index\n",
    "    missing_values_features = data_without_missing_values.iloc[missing_values_indices]\n",
    "    predicted_values = model.predict(imputer.transform(missing_values_features))\n",
    "\n",
    "    data.loc[missing_values_indices, column] = predicted_values\n",
    "\n",
    "output_file = 'data3.xlsx'\n",
    "data.to_excel(output_file, index=False)\n",
    "\n",
    "file_path = 'data3.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "data2['RLH'] = data2['RLH'].astype(int)\n",
    "\n",
    "data2['DATE'] = pd.to_datetime(data2[['YEAR', 'MONTH', 'DAY']])\n",
    "data2['DATE'] = data2['DATE'].dt.date\n",
    "\n",
    "ordered_columns = ['DATE', 'HOUR', 'WDS', 'TMP', 'PRC', 'PRS', 'RLH', 'SSI', 'GSR', 'OUP']\n",
    "data2 = data2[ordered_columns]\n",
    "\n",
    "output_file_updated = 'data3.xlsx'\n",
    "data2.to_excel(output_file_updated, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. İSTATİSTİK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini oku\n",
    "df = pd.read_excel('data3.xlsx')\n",
    "df = df.dropna()\n",
    "\n",
    "# 'DATE' sütununu DateTime formatına dönüştürme ve 'Month' sütununu oluşturma\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df['Month'] = df['DATE'].dt.month\n",
    "\n",
    "# Görselleştirme için verileri hazırlama\n",
    "nem_prc_oranlari = {}\n",
    "\n",
    "nem_araliklari = [(i, i + 10) for i in range(0, 100, 10)]\n",
    "\n",
    "nem_oranlari_list = []  # DataFrame'e dönüştürmek için veri listesi\n",
    "\n",
    "for nem_araligi in nem_araliklari:\n",
    "    alt_sinir, ust_sinir = nem_araligi\n",
    "    filt_nem = (df['RLH'] >= alt_sinir) & (df['RLH'] < ust_sinir)\n",
    "    for ay in range(1, 13):\n",
    "        filt_ay = df['Month'] == ay\n",
    "        filtered_df = df[filt_nem & filt_ay]\n",
    "\n",
    "        yağış_oranı = (filtered_df['PRC'] > 0).mean() * 100\n",
    "        yağışlı_df = filtered_df[filtered_df['PRC'] > 0]\n",
    "        ortalama_prc = yağışlı_df['PRC'].mean() if not yağışlı_df.empty else 0\n",
    "        toplam_saat_sayısı = filtered_df.shape[0]\n",
    "        ortalama_oup = filtered_df['OUP'].mean() if not filtered_df.empty else 0\n",
    "\n",
    "        if not pd.isnull(yağış_oranı) or toplam_saat_sayısı == 0:\n",
    "            nem_oranlari_list.append({'Nem_Araligi': f\"{nem_araligi[0]}-{nem_araligi[1]}\", 'Month': ay,\n",
    "                                      'Yağış_Oranı': yağış_oranı,\n",
    "                                      'Toplam_Saat': toplam_saat_sayısı,\n",
    "                                      'Ortalama_PRC': ortalama_prc,\n",
    "                                      'Ortalama_OUP': ortalama_oup})\n",
    "\n",
    "# Liste üzerinden DataFrame oluşturma\n",
    "nem_oranlari_df = pd.DataFrame(nem_oranlari_list)   \n",
    "\n",
    "# Çizgi grafiği oluşturma\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x='Month', y='Yağış_Oranı', hue='Nem_Araligi', data=nem_oranlari_df)\n",
    "plt.title('Aylara Göre Nem Aralıklarına Göre Yağış Oranı')\n",
    "plt.xlabel('Ay')\n",
    "plt.ylabel('Yağış Oranı (%)')\n",
    "plt.legend(title='Nem Aralığı')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. İSTATİSTİK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini oku ve gereksiz sütunları kaldır\n",
    "df = pd.read_excel('data3.xlsx').dropna()\n",
    "\n",
    "# 'DATE' sütununu datetime olarak işle ve 'Month' sütununu oluştur\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df['Month'] = df['DATE'].dt.month\n",
    "\n",
    "# Sadece OUP değeri sıfır olmayan saatleri içeren bir veri seti oluştur\n",
    "non_zero_oup_hours = df[df['OUP'] != 0]\n",
    "\n",
    "# Ay ve saate göre OUP'nin ortalama değerlerini grupla\n",
    "oup_by_hour_and_month = non_zero_oup_hours.groupby(['Month', 'HOUR'])['OUP'].mean().reset_index()\n",
    "\n",
    "# Ay isimlerini Türkçe olarak tanımla\n",
    "months_dict = {\n",
    "    1: 'Ocak',\n",
    "    2: 'Şubat',\n",
    "    3: 'Mart',\n",
    "    4: 'Nisan',\n",
    "    5: 'Mayıs',\n",
    "    6: 'Haziran',\n",
    "    7: 'Temmuz',\n",
    "    8: 'Ağustos',\n",
    "    9: 'Eylül',\n",
    "    10: 'Ekim',\n",
    "    11: 'Kasım',\n",
    "    12: 'Aralık'\n",
    "}\n",
    "\n",
    "# Ay isimleri ve saatlere göre üretim ortalamalarını içeren bir dosyaya yaz\n",
    "with open('saatlikuretim.txt', 'w') as file:\n",
    "    for month in oup_by_hour_and_month['Month'].unique():\n",
    "        file.write(f\"{months_dict[month]} ayı saatlere göre üretim ortalaması\\n\")\n",
    "        for index, row in oup_by_hour_and_month[oup_by_hour_and_month['Month'] == month].iterrows():\n",
    "            file.write(f\"Saat: {row['HOUR']} - Ortalama OUP: {row['OUP']:.2f}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "# Çubuk grafikler oluşturma\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(12, 10))\n",
    "\n",
    "for i, (month, data) in enumerate(oup_by_hour_and_month.groupby('Month')):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    ax.bar(data['HOUR'], data['OUP'], align='center')\n",
    "    ax.set_title(months_dict[month])\n",
    "    ax.set_ylabel('Ortalama OUP')\n",
    "    ax.set_xticks(data['HOUR'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. İSTATİSTİK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini oku\n",
    "df = pd.read_excel('data3.xlsx')\n",
    "\n",
    "# Rüzgar hızı aralıklarını belirle\n",
    "wds_intervals = [(i, i + 1) for i in range(0, 10)]\n",
    "\n",
    "# Rüzgar hızı aralıklarına göre ortalama üretim değerlerini hesapla\n",
    "wds_oup_means = {}\n",
    "for interval in wds_intervals:\n",
    "    lower, upper = interval\n",
    "    filtered_df = df[(df['WDS'] >= lower) & (df['WDS'] < upper)]\n",
    "    oup_mean = filtered_df['OUP'].mean()\n",
    "    wds_oup_means[interval] = oup_mean\n",
    "\n",
    "# Ortalama üretim değerlerini metin dosyasına yaz\n",
    "with open('rüzgar_oranlari.txt', 'w') as file:\n",
    "    file.write(\"Rüzgar Hızı Aralıklarına Göre Ortalama Üretim Değerleri:\\n\")\n",
    "    for interval, oup_mean in wds_oup_means.items():\n",
    "        file.write(f\"{interval[0]}-{interval[1]} aralığında WDS için Ortalama OUP: {oup_mean:.2f}\\n\")\n",
    "\n",
    "# Pasta grafiği oluşturma\n",
    "labels = [f\"{interval[0]}-{interval[1]}\" for interval in wds_oup_means.keys()]\n",
    "values = list(wds_oup_means.values())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Rüzgar Hızı Aralıklarına Göre Ortalama Üretim Değerleri')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. İSTATİSTİK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data3.xlsx')\n",
    "\n",
    "temperature_intervals = [(i, i + 3) for i in range(-21, 37, 3)]\n",
    "\n",
    "temperature_oup_means = {}\n",
    "for interval in temperature_intervals:\n",
    "    lower, upper = interval\n",
    "    filtered_df = df[(df['TMP'] >= lower) & (df['TMP'] < upper)]\n",
    "    oup_mean = filtered_df['OUP'].mean()\n",
    "    temperature_oup_means[interval] = oup_mean\n",
    "\n",
    "with open('sicaklik_oranlari.txt', 'w') as file:\n",
    "    file.write(\"Sıcaklık Aralıklarına Göre Ortalama Üretim Değerleri:\\n\")\n",
    "    for interval, oup_mean in temperature_oup_means.items():\n",
    "        file.write(f\"{interval[0]}-{interval[1]} aralığında Sıcaklık için Ortalama OUP: {oup_mean:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. İSTATİSTİK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data3.xlsx')\n",
    "\n",
    "gsr_bins = np.linspace(830, 860, 11)  # 0-1000 aralığını 100'erli böler\n",
    "oup_means = df.groupby(pd.cut(df['PRS'], gsr_bins)).mean()['OUP']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(oup_means.index.astype(str), oup_means.values, marker='o')  # .astype(str) kullanarak kategorik indeksleri dizeye çevir\n",
    "plt.title('PRS Aralıklarına Göre Ortalama OUP Değeri')\n",
    "plt.xlabel('PRS Aralığı')\n",
    "plt.ylabel('Ortalama OUP Değeri')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÖZELLİK SKORLARIYLA BÜTÜN MODELLERI KIYASLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'organised_data_final.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "# Veri setinin temel istatistiksel özetini almak\n",
    "summary_stats = data2.describe()\n",
    "summary_stats.to_excel('summary_stats.xlsx')\n",
    "\n",
    "#####\n",
    "\n",
    "file_path = 'data1.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "# Veri setinin temel istatistiksel özetini almak\n",
    "summary_stats = data2.describe()\n",
    "summary_stats.to_excel('summary_stats2.xlsx')\n",
    "\n",
    "#####\n",
    "\n",
    "file_path = 'data2.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "# Veri setinin temel istatistiksel özetini almak\n",
    "summary_stats = data2.describe()\n",
    "summary_stats.to_excel('summary_stats3.xlsx')\n",
    "\n",
    "#####\n",
    "\n",
    "file_path = 'data3.xlsx'\n",
    "data2 = pd.read_excel(file_path)\n",
    "\n",
    "# Veri setinin temel istatistiksel özetini almak\n",
    "summary_stats = data2.describe()\n",
    "summary_stats.to_excel('summary_stats4.xlsx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
